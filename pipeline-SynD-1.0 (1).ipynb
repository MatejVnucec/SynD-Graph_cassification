{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c63975-6740-4a7f-9052-668614a78843",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mamba install pytorch=1.12 torchvision torchaudio cudatoolkit=11.3 -c pytorch -y -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc6d422-e959-492e-a232-0b9b78bb6bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.12.0+cu113.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.12.0+cu113.html\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fd8589-a39b-44b6-ac1c-ab01d896b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mamba install -c conda-forge pyts -q -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b981078-d167-4691-b098-bcfcce2e6a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llvmpy\n",
    "!pip install cython\n",
    "!pip install numba\n",
    "!pip install pandas\n",
    "!pip install networkx\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca3d551-0aab-49a3-8fb9-2b5632323daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from pyts.image import MarkovTransitionField\n",
    "\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "099084cc-ce38-452c-af7e-73fd81e02eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix X weird shape\n",
    "def X_repair(X_temp):\n",
    "    X = np.empty([len(X_temp)-1,len(X_temp[0])], dtype='float64')\n",
    "    k = 0\n",
    "    for i in range(len(X_temp)):\n",
    "        if i != 21019:\n",
    "            for j in range(len(X[0])):\n",
    "                X[i-k][j] = X_temp[i][j]\n",
    "        else:\n",
    "            k = 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a897315-6631-47de-b119-1dbeb9324cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usualy there was a sample with length not equal to the others, that is why shape is weird and we need X_repair\n",
    "def anomaly_finder(X_temp):\n",
    "    for i in range(len(X_temp)):\n",
    "        if len(X_temp[i]) != len(X_temp[0]):\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4781d059-02ef-4ce3-9714-eaf2b2571a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps every utility number and number location in anomaly_numeric()\n",
    "def location_of_labels(Y_temp):\n",
    "    range_labels = np.empty([21-1,3], dtype='<U21')\n",
    "    t = 'n'\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    k = 0\n",
    "    for i in range(len(Y_temp)):\n",
    "        if i != 21019:\n",
    "            if t != Y_temp[i]:\n",
    "                range_labels[count1][0] = count1\n",
    "                range_labels[count1][1] = Y_temp[i]\n",
    "                range_labels[count1][2] = count2\n",
    "                t = Y_temp[i]\n",
    "                count1 += 1\n",
    "            count2 += 1\n",
    "    return range_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "159260cd-78f6-4e6b-9eda-024e965fa008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts words to numbers\n",
    "def anomaly_numeric(Y):\n",
    "    labels = np.empty([len(Y)-1,1], dtype=int)\n",
    "    t = Y[0]\n",
    "    k = 0\n",
    "    count = 0\n",
    "    for i in range(len(Y)):\n",
    "        if i != 21019:\n",
    "            if Y[i] != t:\n",
    "                count += 1\n",
    "                t = Y[i]\n",
    "            labels[i-k] = count\n",
    "        else:\n",
    "            k = 1\n",
    "            \n",
    "    return labels.reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1507f595-2818-4106-bfa8-6c2b85d1668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates the graph \n",
    "def create_graph(n_bins = 150):\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    global lol, output\n",
    "    \n",
    "    #X_temp is original dataset\n",
    "    X_temp = np.load(dataFileName, mmap_mode=None, allow_pickle=True)\n",
    "    \n",
    "    #X is the dataset that we need\n",
    "    X = X_repair(X_temp)\n",
    "    \n",
    "    #Y_temp is original dataset\n",
    "    Y_temp = np.load(labelsFileName, mmap_mode=None, allow_pickle=False)\n",
    "    \n",
    "    #Y is the dataset that we need\n",
    "    Y = anomaly_numeric(Y_temp)\n",
    "    \n",
    "    #for visualisation of what is where in the dataset\n",
    "    lol = location_of_labels(Y_temp)\n",
    "        \n",
    "    MTF = MarkovTransitionField(n_bins = n_bins)\n",
    "    X_gaf = MTF.fit_transform(X)\n",
    "    output = []\n",
    "    \n",
    "    from sklearn.utils import class_weight\n",
    "    global class_weights\n",
    "    class_weights = torch.tensor(class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                                   classes=np.unique(Y),\n",
    "                                                                   y=Y))\n",
    "    def adjToEdgidx(adj_mat):\n",
    "        edge_index = torch.from_numpy(adj_mat).nonzero().t().contiguous()\n",
    "        row, col = edge_index\n",
    "        edge_weight = adj_mat[row, col]#adj_mat[row, col]\n",
    "        return edge_index, edge_weight\n",
    "    \n",
    "    for i, j in enumerate(X_gaf):\n",
    "        edge_index, edge_weight = adjToEdgidx(j)\n",
    "        #Into Data save node values \"x\", edge index from adjacency matrix and edge features/attributes, finally labels       \n",
    "        output.append(Data(x=torch.unsqueeze(torch.tensor(X[i], dtype=torch.double),1), \n",
    "                           edge_index=edge_index, \n",
    "                           edge_attr=torch.unsqueeze(torch.tensor(edge_weight, dtype=torch.double),1), \n",
    "                           y=torch.tensor(Y[i], dtype=torch.long)))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "529b197a-136c-4297-a08a-9994bf305136",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graph Clasification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a01a6d5-aa80-4aae-b121-6486c5e5f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, CrossEntropyLoss\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool, global_max_pool, ChebConv, global_sort_pool\n",
    "from torch.nn import Sequential, BatchNorm1d, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GINConv, GINEConv, GATv2Conv\n",
    "\n",
    "\n",
    "class GINE(torch.nn.Module):\n",
    "    \"\"\"GIN\"\"\"\n",
    "    def __init__(self, dim_h):\n",
    "        super(GINE, self).__init__()\n",
    "        edge_dim = 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv1 = GINEConv(\n",
    "            Sequential(Linear(dim_h, dim_h),\n",
    "                       BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()), edge_dim=edge_dim)\n",
    "        \n",
    "        self.conv2 = GINEConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()), edge_dim=edge_dim)\n",
    "        \n",
    "        self.conv4 = GINEConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()), edge_dim=edge_dim)\n",
    "        \n",
    "        self.conv3 = GINEConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()), edge_dim=edge_dim)\n",
    "        \n",
    "        self.lin1 = Linear(dim_h*4, dim_h*4)\n",
    "        self.lin2 = Linear(dim_h*4, 20)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        # Node embeddings \n",
    "        h1 = self.conv1(x, edge_index, edge_attr=edge_weight)\n",
    "        h2 = self.conv2(h1, edge_index, edge_attr=edge_weight)\n",
    "        h4 = self.conv2(h2, edge_index, edge_attr=edge_weight)\n",
    "        h3 = self.conv3(h4, edge_index, edge_attr=edge_weight)\n",
    "\n",
    "        # Graph-level readout\n",
    "        h1 = global_max_pool(h1, batch)\n",
    "        h2 = global_max_pool(h2, batch)\n",
    "        h3 = global_max_pool(h3, batch)\n",
    "        h4 = global_max_pool(h4, batch)\n",
    "        \n",
    "\n",
    "        # Concatenate graph embeddings\n",
    "        h = torch.cat((h1, h2, h3, h4), dim=1)\n",
    "\n",
    "        # Classifier\n",
    "        h = self.lin1(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62ca21f0-8b61-4394-9d6e-d75edf1b7adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "def trainG(model, loader, epoch, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    with tqdm(loader, unit=\"batch\") as tepoch:\n",
    "         for data in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "            optimizer.zero_grad()\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            loss_function = CrossEntropyLoss(weight=class_weights.to(device))\n",
    "            loss = loss_function(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def testG(model, loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    predicted_categories = []\n",
    "    true_categories = []\n",
    "    with tqdm(loader, unit=\"batch\") as tepoch:\n",
    "        for data in tepoch:\n",
    "      # Iterate in batches over the training/test dataset.\n",
    "            data = data.to(device)\n",
    "            out = model(data)  \n",
    "            pred = out.argmax(dim=1)# Use the class with highest probability.\n",
    "            predicted_categories.append(pred.cpu().detach().numpy())\n",
    "            true_categories.append(data.y.cpu().detach().numpy())\n",
    "            correct += int((pred == data.y).sum())# Check against ground-truth labels.\n",
    "    print(confusion_matrix(true_categories, predicted_categories))\n",
    "    print(classification_report(true_categories, predicted_categories))  \n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "525f4ea5-9707-4b70-9426-8c2d77abda58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_classification(n_bins = 150, batch_size = 64, range_epoch = 10, lr=0.01):\n",
    "    \n",
    "    output = create_graph(n_bins = n_bins)\n",
    "\n",
    "    torch.manual_seed(6406)\n",
    "    train_size = int(0.8 * len(output))\n",
    "    test_size = len(output) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(output, [train_size, test_size])\n",
    "    loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "    #________________Select model_________________________________________________\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model = GINE(32).double().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "\n",
    "    for epoch in range(range_epoch):\n",
    "        result = trainG(model, loader, epoch, optimizer, device)\n",
    "\n",
    "    print(\"Done!\")\n",
    "    score = testG(model, DataLoader(test_dataset, batch_size = 1), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d1824d-254d-4274-863d-ec0e7316a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFileName = 'SynD_data_60.npy'\n",
    "labelsFileName = 'SynD_labels_60.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ccb49f-ac2d-427b-9fac-886252f7d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_classification(n_bins = 200, batch_size = 64, range_epoch = 10, lr=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
